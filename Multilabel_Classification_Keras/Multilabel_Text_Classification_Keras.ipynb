{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains comments from Wikipedia's talk page edits. There are six output labels for each comment: toxic, severe_toxic, obscene, threat, insult and identity_hate. A comment can belong to all of these categories or a subset of these categories, which makes it a multi-label classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "print(toxic_comments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 159571 records and 8 columns. The header of the dataset looks like this : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"The dataset contains 159571 records and 8 columns. The header of the dataset looks like this : \")\n",
    "toxic_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the records where any row contain a null value or empty string.\n",
    "\n",
    "filter = toxic_comments['comment_text'] != \"\"\n",
    "toxic_comments = toxic_comments[filter]\n",
    "\n",
    "# Dropping duplicate text if any\n",
    "\n",
    "toxic_comments = toxic_comments.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You should be fired, you're a moronic wimp who is too lazy to do research. It makes me sick that people like you exist in this world.\n"
     ]
    }
   ],
   "source": [
    "# The comment_text column contains text comments. \n",
    "# Let's print a random comment and then see the labels for the comments.\n",
    "\n",
    "print(toxic_comments['comment_text'][168])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic :  1\n",
      "Severe_toxic:0\n",
      "Obscene:0\n",
      "Threat:0\n",
      "Insult:1\n",
      "Identity_hate:0\n"
     ]
    }
   ],
   "source": [
    "# This is clearly a toxic comment. The associated labels with this comment:\n",
    "print(\"Toxic : \", str(toxic_comments[\"toxic\"][168]))\n",
    "print(\"Severe_toxic:\" + str(toxic_comments[\"severe_toxic\"][168]))\n",
    "print(\"Obscene:\" + str(toxic_comments[\"obscene\"][168]))\n",
    "print(\"Threat:\" + str(toxic_comments[\"threat\"][168]))\n",
    "print(\"Insult:\" + str(toxic_comments[\"insult\"][168]))\n",
    "print(\"Identity_hate:\" + str(toxic_comments[\"identity_hate\"][168]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0      0             0        0       0       0              0\n",
       "1      0             0        0       0       0              0\n",
       "2      0             0        0       0       0              0\n",
       "3      0             0        0       0       0              0\n",
       "4      0             0        0       0       0              0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the comment count for each label.\n",
    "toxic_comments_labels = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]\n",
    "toxic_comments_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e5f06d8348>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot figure\n",
    "toxic_comments_labels.sum(axis=0).plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to create multi-label classification models: Using single dense output layer and using multiple dense output layers.                                                                                                  \n",
    "\n",
    "        1. In the first approach, we can use a single dense layer with six outputs with a sigmoid activation functions and binary cross entropy loss functions. Each neuron in the output dense layer will represent one of the six output labels. The sigmoid activation function will return a value between 0 and 1 for each neuron. If any neuron's output value is greater than 0.5, it is assumed that the comment belongs to the class represented by that particular neuron.                                                                                                                               2. In the second approach we will create one dense output layer for each label. We will have a total of 6 dense layers in the output. Each layer will have its own sigmoid function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text\n",
    "def preprocess_text(text):\n",
    "    #remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    \n",
    "    #single character removal\n",
    "    sentence = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', sentence)\n",
    "    \n",
    "    #remove multiple white spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(toxic_comments[\"comment_text\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "    \n",
    "y = toxic_comments_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert text inputs to Embedded Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GloVe word embeddings to convert text inputs to their numeric counterparts\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single output layer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "LSTM_Layer_1 = LSTM(128)(embedding_layer)\n",
    "dense_layer_1 = Dense(6, activation='sigmoid')(LSTM_Layer_1)\n",
    "model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 200, 100)          14832600  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 14,950,622\n",
      "Trainable params: 118,022\n",
      "Non-trainable params: 14,832,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model_plot4a.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102124 samples, validate on 25532 samples\n",
      "Epoch 1/5\n",
      "102124/102124 [==============================] - 562s 6ms/step - loss: 0.1266 - accuracy: 0.9662 - val_loss: 0.0669 - val_accuracy: 0.9773\n",
      "Epoch 2/5\n",
      "102124/102124 [==============================] - 562s 6ms/step - loss: 0.0622 - accuracy: 0.9790 - val_loss: 0.0582 - val_accuracy: 0.9805\n",
      "Epoch 3/5\n",
      "102124/102124 [==============================] - 566s 6ms/step - loss: 0.0564 - accuracy: 0.9803 - val_loss: 0.0562 - val_accuracy: 0.9807\n",
      "Epoch 4/5\n",
      "102124/102124 [==============================] - 576s 6ms/step - loss: 0.0538 - accuracy: 0.9811 - val_loss: 0.0544 - val_accuracy: 0.9811\n",
      "Epoch 5/5\n",
      "102124/102124 [==============================] - 580s 6ms/step - loss: 0.0522 - accuracy: 0.9815 - val_loss: 0.0539 - val_accuracy: 0.9815\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31915/31915 [==============================] - 35s 1ms/step\n",
      "Test Score: 0.053891471526541015\n",
      "Test Accuracy: 0.9811792373657227\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple output layer structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(toxic_comments[\"comment_text\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))\n",
    "\n",
    "y = toxic_comments[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First output\n",
    "y1_train = y_train[[\"toxic\"]].values\n",
    "y1_test =  y_test[[\"toxic\"]].values\n",
    "\n",
    "# Second output\n",
    "y2_train = y_train[[\"severe_toxic\"]].values\n",
    "y2_test =  y_test[[\"severe_toxic\"]].values\n",
    "\n",
    "# Third output\n",
    "y3_train = y_train[[\"obscene\"]].values\n",
    "y3_test =  y_test[[\"obscene\"]].values\n",
    "\n",
    "# Fourth output\n",
    "y4_train = y_train[[\"threat\"]].values\n",
    "y4_test =  y_test[[\"threat\"]].values\n",
    "\n",
    "# Fifth output\n",
    "y5_train = y_train[[\"insult\"]].values\n",
    "y5_test =  y_test[[\"insult\"]].values\n",
    "\n",
    "# Sixth output\n",
    "y6_train = y_train[[\"identity_hate\"]].values\n",
    "y6_test =  y_test[[\"identity_hate\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 200\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(input_1)\n",
    "LSTM_Layer1 = LSTM(128)(embedding_layer)\n",
    "\n",
    "output1 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output2 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output3 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output4 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output5 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "output6 = Dense(1, activation='sigmoid')(LSTM_Layer1)\n",
    "\n",
    "model = Model(inputs=input_1, outputs=[output1, output2, output3, output4, output5, output6])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 200, 100)     14832600    input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 128)          117248      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 1)            129         lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 14,950,622\n",
      "Trainable params: 118,022\n",
      "Non-trainable params: 14,832,600\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 102124 samples, validate on 25532 samples\n",
      "Epoch 1/5\n",
      "102124/102124 [==============================] - 210s 2ms/step - loss: 3.1744 - dense_14_loss: 0.5570 - dense_15_loss: 0.4829 - dense_16_loss: 0.5485 - dense_17_loss: 0.4947 - dense_18_loss: 0.5461 - dense_19_loss: 0.4570 - dense_14_accuracy: 0.8981 - dense_15_accuracy: 0.9848 - dense_16_accuracy: 0.9425 - dense_17_accuracy: 0.9882 - dense_18_accuracy: 0.9452 - dense_19_accuracy: 0.9874 - val_loss: 0.9892 - val_dense_14_loss: 0.3225 - val_dense_15_loss: 0.0748 - val_dense_16_loss: 0.2281 - val_dense_17_loss: 0.0801 - val_dense_18_loss: 0.2271 - val_dense_19_loss: 0.0504 - val_dense_14_accuracy: 0.9051 - val_dense_15_accuracy: 0.9896 - val_dense_16_accuracy: 0.9461 - val_dense_17_accuracy: 0.9969 - val_dense_18_accuracy: 0.9505 - val_dense_19_accuracy: 0.9919\n",
      "Epoch 2/5\n",
      "102124/102124 [==============================] - 194s 2ms/step - loss: 0.8949 - dense_14_loss: 0.3227 - dense_15_loss: 0.0577 - dense_16_loss: 0.2126 - dense_17_loss: 0.0435 - dense_18_loss: 0.2036 - dense_19_loss: 0.0535 - dense_14_accuracy: 0.9043 - dense_15_accuracy: 0.9902 - dense_16_accuracy: 0.9472 - dense_17_accuracy: 0.9968 - dense_18_accuracy: 0.9504 - dense_19_accuracy: 0.9907 - val_loss: 0.8644 - val_dense_14_loss: 0.3152 - val_dense_15_loss: 0.0598 - val_dense_16_loss: 0.2056 - val_dense_17_loss: 0.0240 - val_dense_18_loss: 0.2050 - val_dense_19_loss: 0.0430 - val_dense_14_accuracy: 0.9052 - val_dense_15_accuracy: 0.9895 - val_dense_16_accuracy: 0.9462 - val_dense_17_accuracy: 0.9969 - val_dense_18_accuracy: 0.9505 - val_dense_19_accuracy: 0.9919\n",
      "Epoch 3/5\n",
      "102124/102124 [==============================] - 194s 2ms/step - loss: 0.8557 - dense_14_loss: 0.3154 - dense_15_loss: 0.0553 - dense_16_loss: 0.2091 - dense_17_loss: 0.0212 - dense_18_loss: 0.2004 - dense_19_loss: 0.0531 - dense_14_accuracy: 0.9043 - dense_15_accuracy: 0.9902 - dense_16_accuracy: 0.9472 - dense_17_accuracy: 0.9968 - dense_18_accuracy: 0.9504 - dense_19_accuracy: 0.9907 - val_loss: 0.8455 - val_dense_14_loss: 0.3148 - val_dense_15_loss: 0.0600 - val_dense_16_loss: 0.2006 - val_dense_17_loss: 0.0208 - val_dense_18_loss: 0.1971 - val_dense_19_loss: 0.0428 - val_dense_14_accuracy: 0.9052 - val_dense_15_accuracy: 0.9895 - val_dense_16_accuracy: 0.9462 - val_dense_17_accuracy: 0.9969 - val_dense_18_accuracy: 0.9505 - val_dense_19_accuracy: 0.9919\n",
      "Epoch 4/5\n",
      "102124/102124 [==============================] - 193s 2ms/step - loss: 0.8467 - dense_14_loss: 0.3146 - dense_15_loss: 0.0541 - dense_16_loss: 0.2068 - dense_17_loss: 0.0206 - dense_18_loss: 0.1975 - dense_19_loss: 0.0517 - dense_14_accuracy: 0.9043 - dense_15_accuracy: 0.9903 - dense_16_accuracy: 0.9472 - dense_17_accuracy: 0.9968 - dense_18_accuracy: 0.9504 - dense_19_accuracy: 0.9907 - val_loss: 0.8446 - val_dense_14_loss: 0.3145 - val_dense_15_loss: 0.0591 - val_dense_16_loss: 0.2006 - val_dense_17_loss: 0.0209 - val_dense_18_loss: 0.1973 - val_dense_19_loss: 0.0429 - val_dense_14_accuracy: 0.9052 - val_dense_15_accuracy: 0.9895 - val_dense_16_accuracy: 0.9462 - val_dense_17_accuracy: 0.9969 - val_dense_18_accuracy: 0.9505 - val_dense_19_accuracy: 0.9919\n",
      "Epoch 5/5\n",
      "102124/102124 [==============================] - 192s 2ms/step - loss: 0.8450 - dense_14_loss: 0.3149 - dense_15_loss: 0.0543 - dense_16_loss: 0.2067 - dense_17_loss: 0.0208 - dense_18_loss: 0.1972 - dense_19_loss: 0.0523 - dense_14_accuracy: 0.9043 - dense_15_accuracy: 0.9903 - dense_16_accuracy: 0.9472 - dense_17_accuracy: 0.9969 - dense_18_accuracy: 0.9505 - dense_19_accuracy: 0.9908 - val_loss: 0.8440 - val_dense_14_loss: 0.3143 - val_dense_15_loss: 0.0589 - val_dense_16_loss: 0.2003 - val_dense_17_loss: 0.0209 - val_dense_18_loss: 0.1971 - val_dense_19_loss: 0.0431 - val_dense_14_accuracy: 0.9052 - val_dense_15_accuracy: 0.9895 - val_dense_16_accuracy: 0.9462 - val_dense_17_accuracy: 0.9969 - val_dense_18_accuracy: 0.9505 - val_dense_19_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=[y1_train, y2_train, y3_train, y4_train, y5_train, y6_train], batch_size=8192, epochs=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31915/31915 [==============================] - 38s 1ms/step\n",
      "Test Score: 0.8442530509574127\n",
      "Test Accuracy: 0.31687453389167786\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x=X_test, y=[y1_test, y2_test, y3_test, y4_test, y5_test, y6_test], verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of only 31% is achieved on the test set via multiple output layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-label text classification is one of the most common text classification problems. In this article, we studied two deep learning approaches for multi-label text classification. In the first approach we used a single dense output layer with multiple neurons where each neuron represented one label.\n",
    "\n",
    "In the second approach, we created separate dense layers for each label with one neuron. Results show that in our case, single output layer with multiple neurons works better than multiple output layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
